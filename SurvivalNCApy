#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Sun Aug 27 01:56:26 2017

@author: mohamed

Survival NCA (Neighborhood Component Analysis)
"""

# Append relevant paths
import os
import sys

def conditionalAppend(Dir):
    """ Append dir to sys path"""
    if Dir not in sys.path:
        sys.path.append(Dir)

cwd = os.getcwd()
conditionalAppend(cwd)

import numpy as np
import SurvivalUtils as sUtils
import tensorflow as tf


#%%============================================================================
# ---- J U N K ----------------------------------------------------------------
#==============================================================================

from scipy.io import loadmat

# Load data
dpath = "/home/mohamed/Desktop/CooperLab_Research/KNN_Survival/Data/SingleCancerDatasets/GBMLGG/Brain_Integ.mat"
Data = loadmat(dpath)

data = np.float32(Data['Integ_X'])
if np.min(Data['Survival']) < 0:
    Data['Survival'] = Data['Survival'] - np.min(Data['Survival']) + 1

Survival = np.int32(Data['Survival'])
Censored = np.int32(Data['Censored'])

# Get split indices
#splitIdxs = sUtils.getSplitIdxs(data)

# Generate survival status - discretized into months
aliveStatus = sUtils.getAliveStatus(Survival, Censored, scale = 30)


#%%============================================================================
# --- P R O T O T Y P E S -----------------------------------------------------
#==============================================================================


#
# Modified from: https://all-umass.github.io/metric-learn/ ...
#                _modules/metric_learn/nca.html#NCA
#

# Initialize A to a scaling matrix
n, d = data.shape
A_init = np.zeros((d, d))
np.fill_diagonal(A_init, 1./(data.max(axis=0)-data.min(axis=0)))
A_init = np.float32(A_init)

#
# Building the compuational graph
#

tf.reset_default_graph()

# Graph input
X = tf.placeholder("float", data.shape)
alive = tf.placeholder("float", aliveStatus.shape)

# transform input
A = tf.Variable(A_init)
AX = tf.matmul(X, A)  # shape (n, d)

# Get mask of available survival status at different time points
avail_mask = tf.cast((alive >= 0), tf.int32)


t = 10 #####
i = 0  #####


def add_Pi_to_cumSum(t, i, cumSum):
    
    """ 
    Gets "probability" of patient i's survival status being correctly 
    predicted at time t and adds it to running cumSum for all points 
    whose survival status is known at time t
    """

    # Get ignore mask -> 
    # give central point and unknown status zero weight
    ignoreMask = tf.Variable(avail_mask[:, t]) # unavailable labels at time t are -> 0
    ignoreMask = ignoreMask[i].assign(0) # central point itself -> 0
    ignoreMask = tf.cast(ignoreMask, tf.float32)
    
    # Calculate normalized feature similarity metric between central point 
    # and those cases with available survival status at time t
    softmax = tf.exp(tf.reduce_sum((AX[i,:] - AX)**2, axis=1)) # shape (n)
    softmax = tf.multiply(softmax, ignoreMask)
    softmax = softmax / tf.reduce_sum(softmax)
    
    # Get label match mask (i.e. i is alive and j is alive, same if i is dead)
    # note there is no need to set central/censored points to zero since this will
    # be multiplied by softmax which already has zeros at these locations
    match = tf.cast(tf.equal(alive[:, t], alive[i, t]), tf.float32)
    
    # Get "probability" of correctly classifying i at time t
    Pi = tf.reduce_sum(tf.multiply(softmax, match))
    
    return cumSum + Pi


def Conditional_Addto_cumSum(t, i, cumSum):
    
        """ 
        Add Pi to cumsum if survival status of i is known at time t 
        """
        
        cumSum = tf.cond(tf.equal(avail_mask[i, t], 1), lambda: add_Pi_to_cumSum(t, i, cumSum), lambda: tf.cast(cumSum, tf.float32))
        
        return cumSum

cumSum_Pred = tf.Variable([0.0])


#%%
